# LSTM & GRU 코드 구현
- ./code/lstm_gru.py
- 3인 페어프로그래밍 (김제우, 김민진, 권혜빈)
### 코드 구현 방식 
    1. 예시 코드를 읽고 주석을 달기
    2. 주석을 빈 py file에 옮겨서 안보고 코드작성
    3. 원래 코드와 비교 분석

### 코드 작성 순서
- 데이터 정의하기
- max_len 구하기, padding하기
- 텐서만들기, 문장 길이 따라 sorting
- LSTM 초기화 & h_0, c_0 초기화
- embedding, pack_padded_sequence 적용, LSTM 통과, pad_packed_sequence 적용
- GRU 생성, Linear, "input_id"(첫단어 모음), hidden 초기화
- Teacher forcing 없이 이전에 얻은 결과를 다음 input으로 이용
- 양방향(Bidirectional), GRU 생성
- 임베딩, pack_padded_sequence, h_0 초기화, gru 통과, pad_packed_sequence

### 배운점
- lstm은 2개의 input(hidden_state,cell)을 입력으로 받고 gru는 1개의 input(hidden_state)를 받는다.
- max()함수와 argmax()의 차이점을 배웠다.
    - max는 max_item들이 담긴 list와 index가 담긴 list 두개를 return한다. 
    - argmax는 index list만을 return 한다.
    - (중요) max함수의 index list를 이용해서 전체 dictionary중 몇번째 index가 softmax의 최대값인지를 확인하는 용도로 사용.
    - dim 설정 중요하다. max로 tensor 전체 원소의 max를 구하게 될수도 sequence별 max를 구하게 될수도 있다.
- bidirectional을 사용하면 hidden_size가 두배가 된다.
- pad->packed->pad과정을 한번더 사용하니 익숙하게 사용했다.
- nn.LSTM은 h_0, c_0을 안써도 된다는 것을 공식문서를 읽고 테스트해보면서 알게 됐다.
- 페어프로그래밍 후기
    - 3번째이지만 벌써 속도면에서 혼자서 프로그래밍 하는것과 비슷하다.
    - 혼자서는 의문이 들면 슬쩍 넘어가는 경우가 많은데 셋이서 있을때 혼잣말처럼 하면 다 같이 해결하고 지나가기 때문에 놓치는 개념이 적어지는것 같다.
    - 그냥 읽을때와 직접 칠때는 완전히 다르다는 점을 많이 느꼈다.
        - 읽을때 10분 걸리던 내용이 직접 작성하니 2시간동안 고민해야하는 내용이다.
    - 팀원 모두가 이해한 코드(합의한 코드)가 있기 때문에 수정하거나 덧붙혀서 더 좋은 코드를 쓰기 좋은것 같다.
    - 변수명 하나를 쓸때도 고민하게 된다.
    - 다른 팀원의 코딩 습관(스킬)들을 알게 돼서 좋은 점을 배울 수 있어서 좋다.

### 해결해야할 의문점
- 공식문서에 h_0부분에 proj_size>0 이라는 조건이 있는데 proj_size가 뭐지?

