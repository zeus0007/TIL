# level3 data제작강의 2일차 듣는중...

## 20211109
- 오늘 한것
    - 자연어처리 데이터 소개
    - 원시 데이터의 수집과 가공
    - 데이터 구축 작업 설계
    - 데이터 구축 가이드라인 작성 기초
    - 라인 자소서 쓰기

- 오늘 배운것
    - 국가 주도 데이터셋
        - 21세기 세종 계획 - 국립 국어원
        - 엑소브레인 - ETRI
        - 모두의 말뭉치 - 국립 국어원
        - AI HUB - NIA
    - 민간 주도 데이터셋
        - KLUE - Upstage
        - KorQuAD - LG CNS
        - KorNLU - kakaobrain
    - 최근 나온것만이 아닌 옛날 것도 꼭 알아두자.
    - Task별 대표 데이터셋
        - QA - SQuAD
        - Machine Translation - WMT
        - Text Summarization - CNN/Daily Mail
        - Dialogue - DSTC, Woz, UDC 등
    - 데이터 수집 하는법
        - 직접 모으기 (크라우드 소싱)
        - 이미 작성된 텍스트 모으기 (기사, 법률, 논문 등)
        - 데이터 수집 목적, 비용, 품질, 법 에 맞춰서 수집을 잘하자.
    - 원시 데이터 전처리
        - 문장의 길이, 중복 문장 제거
        - 용도에 따라 숫자, 기호, 맞춤법, 오탈자 같은 것들 제거
        - 개인정보 제거 or 비식별화
        - 비윤리적 표현 정제
    - 원시 데이터 가공 도구
        - 구글 스프레드 시트
        - 구글 폼
        - Brat
        - Doccano
        - Tagtog
    - 수집이 끝났다면 데이터를 구축하기
        - MATTER cycle
        - MAMA
        - 작업 시작할때 주석 달기 -> 검수하기 무한반복
        - 아래 링크에 데이터 검수할때 지켜야할 절차나 체크리스트 있음.
        - 데이터 평가하기
            - cohens's k 두 사람의 의견이 얼마나 '일치'하는지 -> 두명일때만 사용가능
            - fleiss' k 여러명의 의견이 얼마나 '일치' 하는지
    - 시간 여유있게 잡기
    - 가이드라인 작성 하기
        - 수집을 위한 가이드라인
        - 주석을 위한 가이드라인
        - 검수를 위한 가이드라인
        - 위의 세개에 대한 체크리스트는 아래 링크에
        - 버전관리를 하면 좋다.
        - 구글독스, 노션, 워드, 캐시미싱 많이 씀
        - 사용자들을 위해 가동석 좋게 작성하자.


- 회고
    - 라인 자소서 마무리 제대로 못했다. 정신차리자.
    - 프로젝트할때 이런 가이드라인을 쭉써보면 좋을것이다.
    - 아침에 강의 듣기도 타이머를 맞춰놓고 다같이 달리니까 딴짓 1도 못하고 공부만 달렸다.
    - 환경을 만들어서 억지로 공부를 해서 너무 뿌듯하고 사실 힘들텐데 도와준 팀원들에게 너무 고맙다.
    - 그라운드 룰에 대해 팀원들과 한번 더 이야기 했다.

https://zeuskim.notion.site/6a9d842dbf0b4bfab21ee8a6711a1bb6